{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "796dd307",
   "metadata": {},
   "source": [
    "# DistilBERT Regression (Multi-GPU)\n",
    "\n",
    "This notebook fine-tunes `distilbert-base-uncased` to predict the human toxicity score (`toxicity_human`) using **multiple GPUs** (e.g. Kaggle dual T4).\n",
    "\n",
    "> 将 `NUM_PROCESSES` 设置为 2 可在 Kaggle 上启用双 GPU；若仅有单卡，请改回 1。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5353dc4d",
   "metadata": {},
   "source": [
    "## 0. Environment Setup\n",
    "- 在运行环境中启用 GPU（Kaggle: *Settings → Accelerator → GPU (T4 x2)*）。\n",
    "- 安装所需依赖库。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f64cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q --upgrade transformers datasets accelerate evaluate scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb8bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from datasets import Dataset, DatasetDict\n",
    "from scipy import stats\n",
    "from sklearn.metrics import f1_score, mean_absolute_error, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")\n",
    "\n",
    "print(f\"Available GPUs: {torch.cuda.device_count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb9d7d6",
   "metadata": {},
   "source": [
    "## 1. Configuration\n",
    "更新下面的路径与超参数以匹配当前环境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916a0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据路径设置\n",
    "DATA_ROOT = Path('/kaggle/input/llmimputation/data/parquet')  # TODO: 按需修改\n",
    "IMPUTED_FILE = 'train_text_imputed_mar_knn_30.parquet'          # TODO: 选择要训练的数据集\n",
    "TEST_FILE = 'test.parquet'                                     # 若无独立测试集可改为 None\n",
    "\n",
    "TEXT_COLUMN = 'text'\n",
    "LABEL_COLUMN = 'toxicity_human'\n",
    "LABEL_THRESHOLDS = [1.5, 2.5, 3.5, 4.5]\n",
    "RANDOM_STATE = 42\n",
    "VALID_SIZE = 0.1\n",
    "\n",
    "# 训练相关参数\n",
    "BATCH_SIZE = 16\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "NUM_TRAIN_EPOCHS = 3\n",
    "LEARNING_RATE = 3e-5\n",
    "WARMUP_RATIO = 0.1\n",
    "WEIGHT_DECAY = 0.01\n",
    "MAX_LENGTH = 256\n",
    "\n",
    "# 多 GPU 配置：Kaggle 双 T4 设置为 2；单卡保持 1\n",
    "NUM_PROCESSES = 2\n",
    "USE_FP16 = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee945a3",
   "metadata": {},
   "source": [
    "## 2. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ad7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = DATA_ROOT / IMPUTED_FILE\n",
    "assert train_path.exists(), f\"Missing train file: {train_path}\"\n",
    "\n",
    "df_train = pd.read_parquet(train_path)\n",
    "print(f\"Train rows: {len(df_train):,}\")\n",
    "\n",
    "df_test = None\n",
    "if TEST_FILE:\n",
    "    test_path = DATA_ROOT / TEST_FILE\n",
    "    if test_path.exists():\n",
    "        df_test = pd.read_parquet(test_path)\n",
    "        print(f\"Test rows: {len(df_test):,}\")\n",
    "    else:\n",
    "        print(f\"Warning: TEST_FILE '{TEST_FILE}' not found; skipping test split.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1a85c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train[TEXT_COLUMN].astype(str)\n",
    "y = df_train[LABEL_COLUMN].astype(np.float32)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=VALID_SIZE,\n",
    "    random_state=RANDOM_STATE,\n",
    "    stratify=np.digitize(y, LABEL_THRESHOLDS),\n",
    ")\n",
    "\n",
    "train_dataset = Dataset.from_dict({TEXT_COLUMN: X_train, LABEL_COLUMN: y_train})\n",
    "valid_dataset = Dataset.from_dict({TEXT_COLUMN: X_valid, LABEL_COLUMN: y_valid})\n",
    "\n",
    "datasets_dict = DatasetDict({'train': train_dataset, 'validation': valid_dataset})\n",
    "\n",
    "if df_test is not None:\n",
    "    test_dataset = Dataset.from_dict({\n",
    "        TEXT_COLUMN: df_test[TEXT_COLUMN].astype(str),\n",
    "        LABEL_COLUMN: df_test[LABEL_COLUMN].astype(np.float32),\n",
    "    })\n",
    "    datasets_dict['test'] = test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03cf63b",
   "metadata": {},
   "source": [
    "## 3. Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db2b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'distilbert-base-uncased'\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(example):\n",
    "    model_inputs = tokenizer(\n",
    "        example[TEXT_COLUMN],\n",
    "        padding=False,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "    )\n",
    "    model_inputs['labels'] = example[LABEL_COLUMN]\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = datasets_dict.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=[TEXT_COLUMN, LABEL_COLUMN],\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7220f9a1",
   "metadata": {},
   "source": [
    "## 4. Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa631e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.reshape(-1)\n",
    "    labels = labels.reshape(-1)\n",
    "\n",
    "    mae = mean_absolute_error(labels, predictions)\n",
    "    rmse = mean_squared_error(labels, predictions, squared=False)\n",
    "    pearson = stats.pearsonr(labels, predictions).statistic\n",
    "    spearman = stats.spearmanr(labels, predictions).statistic\n",
    "\n",
    "    true_bins = np.digitize(labels, LABEL_THRESHOLDS)\n",
    "    pred_bins = np.digitize(predictions, LABEL_THRESHOLDS)\n",
    "    macro_f1 = f1_score(true_bins, pred_bins, average='macro')\n",
    "\n",
    "    return {\n",
    "        'mae': mae,\n",
    "        'rmse': rmse,\n",
    "        'pearson': pearson,\n",
    "        'spearman': spearman,\n",
    "        'macro_f1_from_regression': macro_f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2485eb71",
   "metadata": {},
   "source": [
    "## 5. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f2db73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training():\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        model_name,\n",
    "        num_labels=1,\n",
    "    )\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./distilbert_regression_outputs',\n",
    "        evaluation_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='eval_rmse',\n",
    "        greater_is_better=False,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n",
    "        num_train_epochs=NUM_TRAIN_EPOCHS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        warmup_ratio=WARMUP_RATIO,\n",
    "        weight_decay=WEIGHT_DECAY,\n",
    "        logging_steps=100,\n",
    "        fp16=USE_FP16,\n",
    "        report_to='none',\n",
    "        ddp_find_unused_parameters=False,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=tokenized_datasets['train'],\n",
    "        eval_dataset=tokenized_datasets['validation'],\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    trainer.save_model('distilbert_regression_best')\n",
    "\n",
    "    eval_metrics = trainer.evaluate(tokenized_datasets['validation'])\n",
    "    print('Validation metrics:', eval_metrics)\n",
    "\n",
    "    if 'test' in tokenized_datasets:\n",
    "        test_metrics = trainer.evaluate(tokenized_datasets['test'], metric_key_prefix='test')\n",
    "        print('Test metrics:', test_metrics)\n",
    "\n",
    "    torch.save(eval_metrics, 'distilbert_regression_outputs/eval_metrics.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af55352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if NUM_PROCESSES > 1:\n",
    "    from accelerate import notebook_launcher\n",
    "    notebook_launcher(run_training, num_processes=NUM_PROCESSES)\n",
    "else:\n",
    "    run_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5dbbda",
   "metadata": {},
   "source": [
    "## 6. Save Metrics & Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debda283",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import Trainer\n",
    "\n",
    "save_dir = Path('./distilbert_regression_outputs')\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    eval_metrics = torch.load(save_dir / 'eval_metrics.pt')\n",
    "except FileNotFoundError:\n",
    "    eval_metrics = {}\n",
    "\n",
    "if eval_metrics:\n",
    "    import json\n",
    "    with open(save_dir / 'eval_metrics.json', 'w') as f:\n",
    "        json.dump(eval_metrics, f, indent=2)\n",
    "\n",
    "if 'validation' in tokenized_datasets:\n",
    "    model = AutoModelForSequenceClassification.from_pretrained('distilbert_regression_best', num_labels=1)\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    predictions = trainer.predict(tokenized_datasets['validation'])\n",
    "    np.savetxt(\n",
    "        save_dir / 'validation_predictions.csv',\n",
    "        np.vstack([predictions.predictions.reshape(-1), predictions.label_ids]).T,\n",
    "        delimiter=',',\n",
    "        header='pred,label',\n",
    "        comments=''\n",
    "    )\n",
    "    print('Saved validation predictions.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
